{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# running and benchmarking scnaorama"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import scanorama\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import mmread\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:54:14.061108Z",
     "end_time": "2023-04-26T07:54:14.980754Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jzahiri/Documents/Sales/SingleCell/Scanorama/Data/data/hsc/hsc_ss2.npz'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m hsc_ss2 \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/jzahiri/Documents/Sales/SingleCell/Scanorama/Data/data/hsc/hsc_ss2.npz\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:405\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    403\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 405\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    406\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/jzahiri/Documents/Sales/SingleCell/Scanorama/Data/data/hsc/hsc_ss2.npz'"
     ]
    }
   ],
   "source": [
    "#hsc_ss2 = np.load(\"/Users/jzahiri/Documents/Sales/SingleCell/Scanorama/Data/data/hsc/hsc_ss2.npz\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T07:30:33.295845Z",
     "end_time": "2023-04-24T07:30:33.301220Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "genes\n",
      "['X', 'genes']\n",
      "(774, 39109)\n",
      "(39109,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array(['GNAI3', 'PBSN', 'CDC45', ..., 'GM43124', 'GM43323', 'GM7792'],\n      dtype='<U15')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for mtx in hsc_ss2:\n",
    "    print(mtx)\n",
    "print(hsc_ss2.files)\n",
    "print(hsc_ss2['X'].shape)\n",
    "print(hsc_ss2['genes'].shape)\n",
    "hsc_ss2['X'][1:10,:]\n",
    "hsc_ss2['genes']\n",
    "\n",
    "# genes is a vector of gene names\n",
    "# X is the matrix of expressions (?) with dimensions sample*genes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T07:41:17.220049Z",
     "end_time": "2023-04-24T07:41:17.582743Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mtx and npz files\n",
    "It seems that mtx are related to sparce matrix in scipy and npz files are related to zipped archives of the numpy ndarrays."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# running scanorama\n",
    "\n",
    "Running examples from https://github.com/brianhie/scanorama#full-tutorial\n",
    "There are lots of examples in bin folder. All examples assume that the data are in bin/data/ folder.\n",
    "I ran these example mouse_brain.py. It needs gene name (genes.tsv), matrix.mtx along with the cell labels (which is mouse_brain_cluster.txt). It generates two files: tab.npz and tab.genes.txt\n",
    "However, data can be in different format, e.g in hdf5 see process.py\n",
    "\n",
    " Data sets must be numpy array or scipy.sparse.csr_matrix\n",
    "\n",
    "Note:\n",
    "You can merge the datasets based on union of genes or intersect of genes. By default intersect of genes is used. In this case we have to have some common genes across all datasets otherwise: \"Error: No genes found in all datasets, exiting...\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from scanorama import *\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.preprocessing import normalize, LabelEncoder\n",
    "import sys\n",
    "from time import time\n",
    "from bin.process import load_names, process"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:55:47.820968Z",
     "end_time": "2023-04-26T07:55:49.031221Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bin/data/mouse_brain/dropviz/Cerebellum_ALT with 24247 genes and 76250 cells\n",
      "Loaded bin/data/mouse_brain/dropviz/Cortex_noRep5_FRONTALonly with 29463 genes and 194019 cells\n",
      "Loaded bin/data/mouse_brain/dropviz/Cortex_noRep5_POSTERIORonly with 27720 genes and 116432 cells\n",
      "Loaded bin/data/mouse_brain/dropviz/EntoPeduncular with 22631 genes and 33602 cells\n",
      "Found 420303 cells among all datasets\n",
      "Load time: 7.710s\n"
     ]
    }
   ],
   "source": [
    "data_names = [\n",
    "    'bin/data/mouse_brain/dropviz/Cerebellum_ALT',\n",
    "    'bin/data/mouse_brain/dropviz/Cortex_noRep5_FRONTALonly',\n",
    "    'bin/data/mouse_brain/dropviz/Cortex_noRep5_POSTERIORonly',\n",
    "    'bin/data/mouse_brain/dropviz/EntoPeduncular'\n",
    "]\n",
    "\n",
    "# process(data_names, min_trans=100)\n",
    "# it saves files in npz format if they are \"mtx\", \"h5\", or \"txt\"|\"tsv\"|\"txt.gz\"|\"tsv.gz\"\n",
    "# if data_names are folders then it assumes that each folder contains a mtx file named \"matrix.mtx\", and a tsv file for gene names \"genes.tsv\"; if it is a file name then it checks different file types (\"h5\", or \"txt\"|\"tsv\"|\"txt.gz\"|\"tsv.gz\")\n",
    "\n",
    "\n",
    "# \"load_names\" (which calls \"load_data\" which uses scipy.sparse.load_npz for loading data) assumes that datasets are npz files (any full path of a \".npz\" file or a folder containing \"tab.npz\" and \"tab.genes.txt\" files; these files are created by \"process\" function from other data types). It loads datasets and normalize them based on \"norm\" flag. If you are going to do the run \"integrate\" it does the normalization by calling the \"process_data\" so you can set \"norm\" to False.\n",
    "# signature: load_names(data_names, norm=True, log1p=False, verbose=True).\n",
    "t0 = time()\n",
    "datasets, genes_list, n_cells = load_names(data_names)\n",
    "print('Load time: {:.3f}s'.format(time() - t0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:56:03.805631Z",
     "end_time": "2023-04-26T07:56:11.516420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After bin/data/mouse_brain/dropviz/Cerebellum_ALT: 24246 genes\n",
      "After bin/data/mouse_brain/dropviz/Cortex_noRep5_FRONTALonly: 23758 genes\n",
      "After bin/data/mouse_brain/dropviz/Cortex_noRep5_POSTERIORonly: 23204 genes\n",
      "After bin/data/mouse_brain/dropviz/EntoPeduncular: 21080 genes\n",
      "Found 21080 genes among all datasets\n",
      "[[0.         0.14142951 0.05346885 0.14005119]\n",
      " [0.         0.         0.6532053  0.55529433]\n",
      " [0.         0.         0.         0.44235462]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Processing datasets bin/data/mouse_brain/dropviz/Cortex_noRep5_FRONTALonly <=> bin/data/mouse_brain/dropviz/Cortex_noRep5_POSTERIORonly\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "datasets_dimred, datasets, genes = correct(\n",
    "    datasets, genes_list, ds_names=data_names,\n",
    "    return_dimred=True, batch_size=BATCH_SIZE,\n",
    ")\n",
    "print('Batch corrected panoramas: {:.3f}s'.format(time() - t0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "integrated, corrected, genes = scanorama.correct(datasets, genes_list, return_dimred=True)\n",
    "print('Batch corrected and integration in {:.3f}s'\n",
    "      .format(time() - t0))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
